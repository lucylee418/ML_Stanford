{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Supervised Learning\n",
    ": In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.\n",
    "* Regression: predict continuous valued output\n",
    "* Classification: discrete valued output\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Unsupervised Learning\n",
    ": Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables. With unsupervised learning there is no feedback based on the prediction results.\n",
    "* Clustering\n",
    "* Non-clustering: i.e. identifying individual voices and music from a mesh of sounds at a cocktail party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model and Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Model Representation\n",
    "* m : number of training examples\n",
    "* x : input variable or features\n",
    "* y : output variable or target variable\n",
    "* (x, y) : single training example\n",
    "* ($x_i$, $y_i$) : i-th training example\n",
    "\n",
    "\n",
    "* hypothesis function(h)<br>\n",
    " : x -> hypothesis -> y<br>\n",
    " : $h(x) = \\theta_0 + \\theta_1x$ ($\\theta$: parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Cost Function (Mean Squared Error)\n",
    ": We can measure the accuracy of our hypothesis function by using a cost function. This takes an average difference (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's and the actual output y's.\n",
    "* $J(\\theta_0, \\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m}(h(x_i)-y_i)^2$<br>\n",
    "&nbsp;  -> simplify as $J(\\theta_1)$ : function of $J(\\theta_1)$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. start with arbitrary parameters\n",
    "2. update the parameters until convergence<br>\n",
    "&nbsp;$\\theta_j := \\theta_j + \\alpha\\frac{\\partial}{\\partial \\theta_j}J(\\theta_0, \\theta_1)$,  &nbsp; $\\alpha$: learning rate\n",
    "* Applying to the cost function,<br>\n",
    "&nbsp; repeat until convergence: {\n",
    "    $$\\theta_0 := \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(h(x_i)-y_i)$$\n",
    "    $$\\theta_1 := \\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(h(x_i)-y_i)x_i$$ \n",
    "    }<br>\n",
    " cf) 'Batch' Grdient Descent: Each step of grdient descent uses all the training examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Algebra Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Matrix Inverse\n",
    ": must be a square matrix<br>\n",
    "&nbsp; cf) Singular Matrix : A square matrix that does not have a matrix inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4   -0.1  ]\n",
      " [-0.05   0.075]]\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[3, 4], [2, 16]])\n",
    "b = np.linalg.inv(a)        # Inverse Matrix\n",
    "print(b)\n",
    "print(np.matmul(a, b))      # Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Matrix Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0]\n",
      " [3 5 9]]\n",
      "[[1 3]\n",
      " [2 5]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[1, 2, 0], [3, 5, 9]])\n",
    "d = c.transpose()\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
